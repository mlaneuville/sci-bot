{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful, known, withoutpdf = [], [], []\n",
    "for (dirpath, dirnames, fnames) in os.walk('pdf/'):\n",
    "    for fname in fnames:\n",
    "        if fname.endswith('.json'):\n",
    "            with open(os.path.join(dirpath,fname), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            if data['reference']:\n",
    "                for r in data['reference']:\n",
    "                    useful.append(r)\n",
    "            if data['citation']:\n",
    "                for r in data['citation']:\n",
    "                    useful.append(r)\n",
    "\n",
    "            known.append(data['bibcode'])\n",
    "\n",
    "            fn_pdf = fname[:-5] + '.pdf'\n",
    "            fn_xml = fname[:-5] + '.tei.xml'\n",
    "            fn_pdf = os.path.join(dirpath, fn_pdf)\n",
    "            fn_xml = os.path.join(dirpath, fn_xml)\n",
    "\n",
    "            if not os.path.isfile(fn_pdf):\n",
    "                withoutpdf.append((data['bibcode'], data['reference']))\n",
    "\n",
    "            if os.path.isfile(fn_pdf) and not os.path.isfile(fn_xml):\n",
    "                print(fn_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013Sci...339..671W 46\n",
      "2011Sci...331..309W 29\n",
      "2011E&PSL.304..326E 26\n",
      "2003Natur.421..143S 24\n",
      "2000JGR...105.4197J 22\n",
      "2013Sci...339..668Z 22\n",
      "2006RvMG...60..221W 21\n",
      "1995E&PSL.134..501H 20\n",
      "2000JGR...10520417W 19\n",
      "2011PEPI..188...96G 18\n",
      "1997AdSpR..19.1511K 18\n",
      "2011Natur.479..215L 18\n",
      "2011Natur.479..212D 17\n",
      "2019arXiv191205207T 16\n",
      "2006RvMG...60..365S 16\n",
      "2000E&PSL.177..131Z 16\n",
      "1993Sci...260..771K 16\n",
      "2009Sci...323..356G 15\n",
      "2012Sci...335..453S 15\n",
      "2013PNAS..110.8453S 14\n"
     ]
    }
   ],
   "source": [
    "# paper cited a lot but don't have json\n",
    "for r, c in nltk.FreqDist(useful).most_common(30):\n",
    "    #print(r,c)\n",
    "    if r not in known:\n",
    "        print(r,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2017JGRE..122..432H', 80),\n",
       " ('2009M&PS...44...15S', 70),\n",
       " ('2018ApJ...864...75K', 58),\n",
       " ('2019ARA&A..57..617M', 57),\n",
       " ('2018ApJ...867...76L', 52),\n",
       " ('2019CaJES..56..917A', 51),\n",
       " ('2014prpl.conf..883G', 49),\n",
       " ('2018AsBio..18..709C', 46),\n",
       " ('2012P&SS...68..123D', 45),\n",
       " ('2010Icar..208..118H', 45)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing pdf that has the most citations within corpus\n",
    "data = []\n",
    "for idx, refs in withoutpdf:\n",
    "    if refs is None:\n",
    "        continue\n",
    "    cites = [r for r in refs if r in known]\n",
    "    data.append((idx, len(cites)))\n",
    "\n",
    "sorted(data, key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grobidclient import grobidclient\n",
    "import time\n",
    "def _parsepdf(path):\n",
    "        service = 'processFulltextDocument'\n",
    "        generateIDs = False\n",
    "        consolidate_header = False\n",
    "        consolidate_citations = False\n",
    "        force = False\n",
    "        teiCoordinates = False\n",
    "\n",
    "        client = grobidclient(config_path='grobid-config.json')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        client.process(path, path, 20, service, generateIDs,\n",
    "                       consolidate_header, consolidate_citations, force,\n",
    "                       teiCoordinates)\n",
    "\n",
    "        runtime = round(time.time() - start_time, 3)\n",
    "        print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n",
      "15 PDF files to process\n",
      "pdf/10.1073/pnas.1111493108.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1304208111.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1417490112.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1309107110.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1013480108.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.262514499.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.0610903104.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073//pnas.0407173101.pdf\n",
      "pdf/10.1073/pnas.1319909110.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1114043109.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1300341110.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073//pnas.0507469102.pdf\n",
      "pdf/10.1073/pnas.1110051108.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073/pnas.1811074116.tei.xml already exist, skipping... (use --force to reprocess pdf input files)\n",
      "pdf/10.1073//pnas.0903518106.pdf\n",
      "2.429\n"
     ]
    }
   ],
   "source": [
    "_parsepdf('pdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2138/am-2018-6462\n",
      "10.3847/1538-4357/aad69c\n",
      "10.1007/978-3-319-55333-7\n",
      "10.1007/978-3-319-55333-7_76\n",
      "10.1089/ast.2018.1958\n",
      "10.3390/atmos10100600\n",
      "10.1029/2019JE006117\n",
      "10.1038/d41586-019-02811-1\n",
      "10.1073/pnas.1811074116\n",
      "10.1126/science.257.5071.766 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('refs.txt', 'r') as f:\n",
    "    refs = f.read().split('\\n')\n",
    "    \n",
    "for r in refs:\n",
    "    print(r)\n",
    "    subprocess.run(['python3', 'sci-bot.py', '--doi', r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
